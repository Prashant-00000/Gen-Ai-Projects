# -*- coding: utf-8 -*-
"""End-to-End RAG using LLaMA2 + LlamaIndex.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p4_wBMKthgTONQ0f1oIyxSodwW-1aolL
"""

!pip install llama-index
!pip install transformers accelerate bitsandbytes
!pip install sentence-transformers

from llama_index.llms.huggingface import HuggingFaceLLM
from llama_index.core import Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

Settings.embed_model = HuggingFaceEmbedding(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)


llm = HuggingFaceLLM(
    model_name="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    tokenizer_name="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    context_window=2048,
    max_new_tokens=256,
    device_map="auto"
)

Settings.llm = llm

from llama_index.core import SimpleDirectoryReader

documents = SimpleDirectoryReader(input_files=["/content/tt.pdf"]).load_data()

from llama_index.core import VectorStoreIndex

index = VectorStoreIndex.from_documents(documents)

query_engine = index.as_query_engine()

response = query_engine.query("What is this document about?")

print(response)

!pip install llama-index-embeddings-huggingface