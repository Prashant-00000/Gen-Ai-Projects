# -*- coding: utf-8 -*-
"""Agentic RAG using CrewAI  Learn:  Agents + Retrieval combination  Dynamic decision making.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lYDGQc9fIAfX-3uHniQIB4NwFDaQXb5r
"""

pip install crewai langchain langchain-community faiss-cpu sentence-transformers transformers accelerate

from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

loader = TextLoader("kn.txt")
documents = loader.load()

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

vectorstore = FAISS.from_documents(documents, embeddings)

retriever = vectorstore.as_retriever()

def retrieve_docs(query):
    docs = retriever.get_relevant_documents(query)
    return "\n".join([doc.page_content for doc in docs])

from transformers import pipeline
from langchain_community.llms import HuggingFacePipeline

hf_pipeline = pipeline(
    "text-generation",
    model="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    max_new_tokens=150,
    temperature=0.0,
    do_sample=False,
    device_map="auto"
)

llm = HuggingFacePipeline(pipeline=hf_pipeline)

from crewai import Agent, Task, Crew
from crewai.tools import tool

@tool("Knowledge Base Search")
def retrieval_tool(query: str) -> str:
    """Search the knowledge base for relevant information."""
    return retrieve_docs(query)

research_agent = Agent(
    role="Research Specialist",
    goal="Retrieve relevant information before answering.",
    backstory="Expert in searching knowledge bases.",
    verbose=True,
    allow_delegation=False,
    tools=[retrieval_tool],
    llm=llm
)

answer_agent = Agent(
    role="Answer Generator",
    goal="Generate accurate answers using retrieved information.",
    backstory="Expert in explaining concepts clearly.",
    verbose=True,
    allow_delegation=False,
    llm=llm
)

research_task = Task(
    description="Search the knowledge base for information about: {question}",
    agent=research_agent,
    expected_output="Relevant documents"
)

answer_task = Task(
    description="Use the retrieved documents to answer: {question}",
    agent=answer_agent,
    expected_output="Final answer"
)

crew = Crew(
    agents=[research_agent, answer_agent],
    tasks=[research_task, answer_task],
    verbose=True
)

from crewai import LLM

llm = LLM(
    model="ollama/tinyllama"
)

!pip install litellm

result = crew.kickoff(inputs={"question": "What is CrewAI?"})
print(result)

